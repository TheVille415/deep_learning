{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intensive Retake 1point2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fCTM92-IFabog2IyTcQnGUNiW_nDHJ80",
      "authorship_tag": "ABX9TyNgjWlxyroJYXhFo9kDFq6f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheVille415/deep_learning/blob/master/Intensive_Retake_1point2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU9rUjOHNumy"
      },
      "source": [
        "A Single Neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqFOEEuzfrQF"
      },
      "source": [
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "\n",
        "# # Create a network with 1 linear unit\n",
        "# # input_shape = what we are looking for - total columns\n",
        "# model = keras.Sequential([\n",
        "#     layers.Dense(units=1, input_shape=[3])\n",
        "# ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xsd0teVwN5MF"
      },
      "source": [
        "Deep Neural Networks:\n",
        "<br>\n",
        "activation function = some function we use for each layers output\n",
        "we will be using rectified linear unit or ReLU\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGEyod58SSya"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    # the hidden ReLU layers\n",
        "    layers.Dense(512, activation='relu', input_shape=[11]),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    # the linear output layer \n",
        "    layers.Dense(units=1),\n",
        "])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwCToQmVVeAA"
      },
      "source": [
        "# Stochastic Gradient Descent: The loss function\n",
        "<br>\n",
        "A common loss function for regression problems is the mean absolute error or MAE. For each prediction y_pred, MAE measures the disparity from the true target y_true by an absolute difference abs(y_true - y_pred).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCCNgovMV8P-"
      },
      "source": [
        "# Stochastic Gradient Descent: The Optimizer\n",
        "<br>\n",
        "The optimizer is an algorithm that adjusts the weights to minimize the loss. Each iteration's sample of training data is called a minibatch (or often just \"batch\"), while a complete round of the training data is called an epoch. The number of epochs you train for is how many times the network will see each training example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZRZq99Wfb1I"
      },
      "source": [
        "# Learning rate and batch size:\n",
        "\n",
        "The size of these shifts is determined by the learning rate. A smaller learning rate means the network needs to see more minibatches before its weights converge to their best values.\n",
        "\n",
        "**Adam** is an SGD algorithm that has an adaptive learning rate that makes it suitable for most problems without any parameter tuning (it is \"self tuning\", in a sense). Adam is a great general-purpose optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU67Qc1Vgn0i"
      },
      "source": [
        "Importing Kaggle Redwine Quality Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbj8jM6LhQTs"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np3HdM3OgnN_",
        "outputId": "8eed3027-79d3-482a-c3a9-d38742f60953"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ELDw7bqVhILI",
        "outputId": "4b2783cc-b6df-44e4-eaf9-ce1481f2655e"
      },
      "source": [
        "wine_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/winequality-red.csv')\n",
        "wine_df"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.47</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.067</td>\n",
              "      <td>18.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.99549</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0               7.4             0.700         0.00  ...       0.56      9.4        5\n",
              "1               7.8             0.880         0.00  ...       0.68      9.8        5\n",
              "2               7.8             0.760         0.04  ...       0.65      9.8        5\n",
              "3              11.2             0.280         0.56  ...       0.58      9.8        6\n",
              "4               7.4             0.700         0.00  ...       0.56      9.4        5\n",
              "...             ...               ...          ...  ...        ...      ...      ...\n",
              "1594            6.2             0.600         0.08  ...       0.58     10.5        5\n",
              "1595            5.9             0.550         0.10  ...       0.76     11.2        6\n",
              "1596            6.3             0.510         0.13  ...       0.75     11.0        6\n",
              "1597            5.9             0.645         0.12  ...       0.71     10.2        5\n",
              "1598            6.0             0.310         0.47  ...       0.66     11.0        6\n",
              "\n",
              "[1599 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "Bykzt50hhix2",
        "outputId": "f1ab27ed-ff2c-4e37-d794-82f7d0654005"
      },
      "source": [
        "# creating and training the data\n",
        "df_train = wine_df.sample(frac=0.7, random_state=0)\n",
        "df_valid = wine_df.drop(df_train.index)\n",
        "display(df_train.head(4))\n",
        "# min of quality is 0 max is 10"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1109</th>\n",
              "      <td>10.8</td>\n",
              "      <td>0.470</td>\n",
              "      <td>0.43</td>\n",
              "      <td>2.10</td>\n",
              "      <td>0.171</td>\n",
              "      <td>27.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.99820</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.76</td>\n",
              "      <td>10.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1032</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.820</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.10</td>\n",
              "      <td>0.095</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.99854</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.53</td>\n",
              "      <td>9.6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>9.1</td>\n",
              "      <td>0.290</td>\n",
              "      <td>0.33</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.063</td>\n",
              "      <td>13.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.99516</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.84</td>\n",
              "      <td>11.7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>10.2</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.053</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.99820</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.42</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "1109           10.8             0.470         0.43  ...       0.76     10.8        6\n",
              "1032            8.1             0.820         0.00  ...       0.53      9.6        5\n",
              "1002            9.1             0.290         0.33  ...       0.84     11.7        7\n",
              "487            10.2             0.645         0.36  ...       0.42     10.0        6\n",
              "\n",
              "[4 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrGRYfuah6Wb"
      },
      "source": [
        "# Scaling the data [0,1]\n",
        "max_ = df_train.max(axis=0)\n",
        "min_ = df_train.min(axis=0)\n",
        "df_train = (df_train - min_) / (max_ - min_)\n",
        "df_valid = (df_valid - min_) / (max_ - min_)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGeAzkcDiOdT"
      },
      "source": [
        "# Splitting features and target\n",
        "X_train = df_train.drop('quality', axis=1)\n",
        "y_train = df_train['quality']\n",
        "\n",
        "X_valid = df_valid.drop('quality', axis=1)\n",
        "y_valid = df_valid['quality']"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuDbdr-SiZ_m",
        "outputId": "8dce97a3-8bef-499c-fd91-4c5bafd8954d"
      },
      "source": [
        "print(X_train.shape)\n",
        "# after printing we see we have 11 columns or 11 inputs"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1119, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3JbVqE-VlbT"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"mae\",\n",
        ")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC1Bg20QijrG",
        "outputId": "ce207d51-c30b-49e2-fa28-c16f096d8200"
      },
      "source": [
        "# time to start training\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    batch_size=256,\n",
        "    epochs=10,\n",
        ")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 1s 56ms/step - loss: 0.3124 - val_loss: 0.1340\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1540 - val_loss: 0.1312\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1334 - val_loss: 0.1286\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.1208 - val_loss: 0.1331\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1176 - val_loss: 0.1126\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.1164 - val_loss: 0.1151\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1122 - val_loss: 0.1051\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1091 - val_loss: 0.1104\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1073 - val_loss: 0.1016\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1044 - val_loss: 0.1033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koiwb86Tv1nk"
      },
      "source": [
        "# Evaluating performance through loss comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjRS1ymJuTkD"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 0.4])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [Dollars')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "6ln6lXKTt-sn",
        "outputId": "773a0293-29ce-4fb9-e720-1781708b9b01"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg1FUwrKsrpb"
      },
      "source": [
        "When a model learns **signal** *both curves go down*, but when it learns **noise** *a gap is created in the curves.*\n",
        "<br>\n",
        "**Underfitting** the training set is when the loss is not as low as it could be because the model hasn't learned enough signal. **Overfitting** the training set is when the loss is not as low as it could be because the model learned too much noise.\n",
        "<br>\n",
        "You can increase the capacity of a network either by making it *wider* (more units to existing layers) or by making it *deeper* (adding more layers). Wider networks have an easier time learning more linear relationships, while deeper networks prefer more nonlinear ones. Which is better just depends on the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_Pl5ts1x_X0"
      },
      "source": [
        "A callback is just a function you want run every so often while the network trains. The early stopping callback will run after every epoch"
      ]
    }
  ]
}